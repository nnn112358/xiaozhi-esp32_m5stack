

## 1. 全体的な流れの概要

1. **デバイス側の初期化**  
   - デバイスの電源投入、`Application`の初期化：  
     - オーディオコーデック、ディスプレイ、LEDなどの初期化  
     - ネットワーク接続  
     - `Protocol`インターフェースを実装するWebSocketプロトコルインスタンス（`WebsocketProtocol`）の作成と初期化  
   - メインループに入り、イベント（音声入力、音声出力、スケジュールされたタスクなど）を待機。

2. **WebSocket接続の確立**  
   - デバイスが音声セッションを開始する必要がある時（ユーザーの音声認識、手動ボタントリガーなど）、`OpenAudioChannel()`を呼び出し：  
     - 設定からWebSocket URLを取得
     - いくつかのリクエストヘッダー（`Authorization`, `Protocol-Version`, `Device-Id`, `Client-Id`）を設定  
     - `Connect()`を呼び出してサーバーとWebSocket接続を確立  

3. **クライアント"hello"メッセージの送信**  
   - 接続成功後、デバイスはJSONメッセージを送信。例：  
   ```json
   {
     "type": "hello",
     "version": 1,
     "transport": "websocket",
     "audio_params": {
       "format": "opus",
       "sample_rate": 16000,
       "channels": 1,
       "frame_duration": 60
     }
   }
   ```
   - ここで`"frame_duration"`の値は`OPUS_FRAME_DURATION_MS`（例：60ms）に対応します。

4. **サーバーの"hello"応答**  
   - デバイスはサーバーから`"type": "hello"`を含むJSONメッセージの返信を待ち、`"transport": "websocket"`が一致するかチェックします。  
   - 一致した場合、サーバーが準備完了と見なし、音声チャンネルの開通成功をマークします。  
   - タイムアウト時間（デフォルト10秒）内に正しい応答が得られない場合、接続失敗と見なしネットワークエラーコールバックをトリガーします。

5. **その後のメッセージ交換**  
   - デバイス側とサーバー側間で主に2種類のデータを送信：  
     1. **バイナリ音声データ**（Opusエンコード）  
     2. **テキストJSONメッセージ**（チャット状態、TTS/STTイベント、IoTコマンドなどの伝送用）  

   - コード内で、受信コールバックは主に以下に分かれます：  
     - `OnData(...)`:  
       - `binary`が`true`の場合、音声フレームと見なし、デバイスはこれをOpusデータとしてデコードします。  
       - `binary`が`false`の場合、JSONテキストと見なし、デバイス側でcJSONを使用して解析し、対応するビジネスロジック処理を行います（下記メッセージ構造参照）。  

   - サーバーまたはネットワークが切断された場合、`OnDisconnected()`コールバックがトリガーされます：  
     - デバイスは`on_audio_channel_closed_()`を呼び出し、最終的にアイドル状態に戻ります。

6. **WebSocket接続の閉鎖**  
   - デバイスが音声セッションを終了する必要がある時、`CloseAudioChannel()`を呼び出して能動的に接続を切断し、アイドル状態に戻ります。  
   - またはサーバー側が能動的に切断した場合も、同様のコールバックフローを引き起こします。

---

## 2. 共通リクエストヘッダー

WebSocket接続確立時、コード例では以下のリクエストヘッダーを設定：

- `Authorization`: アクセストークンを格納、形式は`"Bearer <token>"`  
- `Protocol-Version`: 例では固定で`"1"`  
- `Device-Id`: デバイス物理NIC MACアドレス  
- `Client-Id`: デバイスUUID（アプリケーション内でデバイスを一意に識別）

これらのヘッダーはWebSocketハンドシェイクと共にサーバーに送信され、サーバーは必要に応じて検証、認証などを行うことができます。

---

## 3. JSONメッセージ構造

WebSocketテキストフレームはJSON形式で伝送され、以下は一般的な`"type"`フィールドとその対応するビジネスロジックです。メッセージに記載されていないフィールドが含まれている場合、オプションまたは特定の実装詳細の可能性があります。

### 3.1 クライアント→サーバー

1. **Hello**  
   - 接続成功後、クライアントが送信し、サーバーに基本パラメータを通知。  
   - 例：
     ```json
     {
       "type": "hello",
       "version": 1,
       "transport": "websocket",
       "audio_params": {
         "format": "opus",
         "sample_rate": 16000,
         "channels": 1,
         "frame_duration": 60
       }
     }
     ```

2. **Listen**  
   - クライアントが録音リスニングを開始または停止することを示す。  
   - 一般的なフィールド：  
     - `"session_id"`：セッション識別子  
     - `"type": "listen"`  
     - `"state"`：`"start"`, `"stop"`, `"detect"`（ウェイクワード検出がトリガーされた）  
     - `"mode"`：`"auto"`, `"manual"`または`"realtime"`、認識モードを表す。  
   - 例：リスニング開始  
     ```json
     {
       "session_id": "xxx",
       "type": "listen",
       "state": "start",
       "mode": "manual"
     }
     ```

3. **Abort**  
   - 現在の発話（TTS再生）または音声チャンネルを終了。  
   - 例：
     ```json
     {
       "session_id": "xxx",
       "type": "abort",
       "reason": "wake_word_detected"
     }
     ```
   - `reason`の値は`"wake_word_detected"`またはその他。

4. **Wake Word Detected**  
   - クライアントがサーバーにウェイクワード検出を通知するために使用。  
   - 例：
     ```json
     {
       "session_id": "xxx",
       "type": "listen",
       "state": "detect",
       "text": "你好小明"
     }
     ```

5. **IoT**  
   - 現在のデバイスのIoT関連情報を送信：  
     - **Descriptors**（デバイス機能、属性などの記述）  
     - **States**（デバイス状態のリアルタイム更新）  
   - 例：  
     ```json
     {
       "session_id": "xxx",
       "type": "iot",
       "descriptors": { ... }
     }
     ```
     または
     ```json
     {
       "session_id": "xxx",
       "type": "iot",
       "states": { ... }
     }
     ```

---

### 3.2 サーバー→クライアント

1. **Hello**  
   - サーバー側が返すハンドシェイク確認メッセージ。  
   - `"type": "hello"`と`"transport": "websocket"`を含む必要があります。  
   - `audio_params`を含む場合があり、サーバーが期待する音声パラメータ、またはクライアントと合わせた設定を示します。  
   - 正常に受信後、クライアントはイベントフラグを設定し、WebSocketチャンネルが準備完了であることを示します。

2. **STT**  
   - `{"type": "stt", "text": "..."}`
   - サーバー側がユーザーの音声を認識したことを示します（例：音声テキスト変換結果）  
   - デバイスはこのテキストを画面に表示し、その後応答などのフローに入る可能性があります。

3. **LLM**  
   - `{"type": "llm", "emotion": "happy", "text": "😀"}`
   - サーバーがデバイスに表情アニメーション/UI表現の調整を指示。  

4. **TTS**  
   - `{"type": "tts", "state": "start"}`：サーバーがTTS音声の配信準備、クライアントは"speaking"再生状態に入る。  
   - `{"type": "tts", "state": "stop"}`：今回のTTS終了を示す。  
   - `{"type": "tts", "state": "sentence_start", "text": "..."}`
     - デバイスのインターフェースに現在再生または読み上げ予定のテキストセグメントを表示させる（例：ユーザーに表示するため）。  

5. **IoT**  
   - `{"type": "iot", "commands": [ ... ]}`
   - サーバーがデバイスにIoTアクション指令を送信、デバイスは解析して実行（ライトの点灯、温度設定など）。

6. **音声データ：バイナリフレーム**  
   - サーバーが音声バイナリフレーム（Opusエンコード）を送信する時、クライアントはデコードして再生。  
   - クライアントが"listening"（録音）状態にある場合、受信した音声フレームは競合を防ぐため無視またはクリアされます。

---

## 4. 音声エンコード・デコード

1. **クライアントの録音データ送信**  
   - 音声入力は可能なエコーキャンセレーション、ノイズリダクション、ボリューム増幅後、Opusエンコードによりバイナリフレームとしてパッケージ化してサーバーに送信。  
   - クライアントが各エンコード時に生成するバイナリフレームサイズがNバイトの場合、WebSocketの**binary**メッセージでこのデータを送信します。

2. **クライアントの受信音声再生**  
   - サーバーからバイナリフレームを受信した時、同様にOpusデータと見なします。  
   - デバイス側でデコードを行い、その後音声出力インターフェースで再生。  
   - サーバーの音声サンプリングレートがデバイスと一致しない場合、デコード後に再サンプリングを行います。

---

## 5. 一般的な状態遷移

以下、デバイス側の主要な状態遷移を簡述し、WebSocketメッセージとの対応を示します：

1. **Idle** → **Connecting**  
   - ユーザートリガーまたはウェイクアップ後、デバイスは`OpenAudioChannel()`を呼び出し → WebSocket接続確立 → `"type":"hello"`送信。  

2. **Connecting** → **Listening**  
   - 接続確立成功後、`SendStartListening(...)`を継続実行すると録音状態に入る。この時デバイスはマイクロフォンデータを継続的にエンコードしてサーバーに送信。  

3. **Listening** → **Speaking**  
   - サーバーTTS Startメッセージ（`{"type":"tts","state":"start"}`）受信 → 録音停止し受信音声を再生。  

4. **Speaking** → **Idle**  
   - サーバーTTS Stop（`{"type":"tts","state":"stop"}`） → 音声再生終了。自動リスニングを継続しない場合はIdleに戻る；自動ループが設定されている場合は再度Listeningに入る。  

5. **Listening** / **Speaking** → **Idle**（異常または能動的中断に遭遇）  
   - `SendAbortSpeaking(...)`または`CloseAudioChannel()`呼び出し → セッション中断 → WebSocket閉鎖 → 状態がIdleに戻る。  

---

## 6. エラー処理

1. **接続失敗**  
   - `Connect(url)`が失敗を返すか、サーバー"hello"メッセージ待機中にタイムアウトした場合、`on_network_error_()`コールバックをトリガー。デバイスは「サービスに接続できません」または類似のエラーメッセージを表示。

2. **サーバー切断**  
   - WebSocketが異常切断した場合、`OnDisconnected()`コールバック：  
     - デバイスは`on_audio_channel_closed_()`をコールバック  
     - Idleまたはその他の再試行ロジックに切り替え。

---

## 7. その他の注意事項

1. **認証**  
   - デバイスは`Authorization: Bearer <token>`設定により認証を提供、サーバー側で有効性を検証する必要があります。  
   - トークンが期限切れまたは無効の場合、サーバーはハンドシェイクを拒否するか、その後切断することができます。

2. **セッション制御**  
   - コード内の一部メッセージには`session_id`が含まれ、独立した対話または操作を区別するために使用。サーバー側は必要に応じて異なるセッションの分離処理を行うことができ、WebSocketプロトコルは空白です。

3. **音声ペイロード**  
   - コード内ではデフォルトでOpus形式を使用し、`sample_rate = 16000`、モノラルに設定。フレーム長は`OPUS_FRAME_DURATION_MS`で制御され、一般的に60ms。帯域幅や性能に応じて適切に調整可能。

4. **IoT指令**  
   - `"type":"iot"`メッセージのユーザー側コードは`thing_manager`と接続して具体的なコマンドを実行し、デバイスのカスタマイゼーションにより異なります。サーバー側は配信形式がクライアント側と一致することを確保する必要があります。

5. **エラーまたは異常JSON**  
   - JSONに必要なフィールドが欠けている場合、例えば`{"type": ...}`、クライアントはエラーログを記録（`ESP_LOGE(TAG, "Missing message type, data: %s", data);`）し、いかなるビジネスも実行しません。

---

## 8. メッセージ例

以下、典型的な双方向メッセージ例（フロー簡略化図解）：

1. **クライアント → サーバー**（ハンドシェイク）
   ```json
   {
     "type": "hello",
     "version": 1,
     "transport": "websocket",
     "audio_params": {
       "format": "opus",
       "sample_rate": 16000,
       "channels": 1,
       "frame_duration": 60
     }
   }
   ```

2. **サーバー → クライアント**（ハンドシェイク応答）
   ```json
   {
     "type": "hello",
     "transport": "websocket",
     "audio_params": {
       "sample_rate": 16000
     }
   }
   ```

3. **クライアント → サーバー**（リスニング開始）
   ```json
   {
     "session_id": "",
     "type": "listen",
     "state": "start",
     "mode": "auto"
   }
   ```
   同時にクライアントはバイナリフレーム（Opusデータ）の送信を開始。

4. **サーバー → クライアント**（ASR結果）
   ```json
   {
     "type": "stt",
     "text": "ユーザーが話した言葉"
   }
   ```

5. **サーバー → クライアント**（TTS開始）
   ```json
   {
     "type": "tts",
     "state": "start"
   }
   ```
   続いてサーバーはバイナリ音声フレームをクライアントに送信して再生。

6. **サーバー → クライアント**（TTS終了）
   ```json
   {
     "type": "tts",
     "state": "stop"
   }
   ```
   クライアントは音声再生を停止し、さらなる指令がない場合はアイドル状態に戻る。

---

## 9. まとめ

このプロトコルはWebSocket上でJSONテキストとバイナリ音声フレームを伝送することにより、音声ストリームアップロード、TTS音声再生、音声認識と状態管理、IoT指令配信などの機能を完成させます。その核心的特徴：

- **ハンドシェイク段階**：`"type":"hello"`を送信し、サーバーの返信を待機。  
- **音声チャンネル**：Opusエンコードのバイナリフレームによる双方向音声ストリーム伝送を採用。  
- **JSONメッセージ**：`"type"`を核心フィールドとして異なるビジネスロジックを識別し、TTS、STT、IoT、WakeWordなどを含む。  
- **拡張性**：実際のニーズに応じてJSONメッセージにフィールドを追加、またはheadersで追加認証を行うことが可能。

サーバーとクライアントは事前に各種メッセージのフィールド意味、時系列ロジック、エラー処理ルールを約定し、通信の円滑化を保証する必要があります。上記情報は基礎文書として、後続の接続、開発、拡張に便利です。
